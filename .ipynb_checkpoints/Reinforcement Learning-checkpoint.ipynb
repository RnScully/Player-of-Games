{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:55:06.983587Z",
     "start_time": "2020-03-02T11:55:04.959270Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"/home/robert/Player-of-Games/src\")\n",
    "\n",
    "\n",
    "from g2048 import Game2048\n",
    "from train_2048 import empties_state\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tools import update_progress\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:55:07.029763Z",
     "start_time": "2020-03-02T11:55:06.985392Z"
    },
    "code_folding": [
     23,
     45,
     99,
     111,
     184
    ]
   },
   "outputs": [],
   "source": [
    "class RL_Player():\n",
    "    def __init__(self, reward_depth = 5, model = None, demo = False, headless = False):\n",
    "        self.reward = 0\n",
    "        self.gamma = 0.9\n",
    "        self.long_memory =[]\n",
    "        # self.dataframe = pd.DataFrame()\n",
    "        self.oldest_mem = 0\n",
    "        self.target = []\n",
    "        self.X = []\n",
    "        self.learning_rate = .005\n",
    "        self.reward_depth = reward_depth\n",
    "        if model == None:\n",
    "            self.model = self.neural_net()\n",
    "        else:\n",
    "            self.model = keras.models.load_model(model)\n",
    "        self.headless = headless \n",
    "        self.demo = demo\n",
    "        self.bad_move = 0\n",
    "        self.memory = [[] for _ in range(self.reward_depth)]\n",
    "        self.debug = 0\n",
    "        self.debug1 = 0\n",
    "        self.debug2 = -1\n",
    "    \n",
    "    def tokenize_board(self, board):\n",
    "        '''method takes the game board and tokenizes all the arrays into 16 other arrays for if there's a 2, a 4, an 8, etc in a location to just a 1. hopefully...makes matching better\n",
    "        Attributes \n",
    "        game( game2084 object): the game. \n",
    "        Returns\n",
    "        tokenized 256x1 tokenization of all* possible game states. \n",
    "        \n",
    "        * does not account for the 136k tile. I just..don't expect to need that. Frankly, 16k and 32k seem a reach\n",
    "        '''\n",
    "        tokenized = np.array([])\n",
    "        \n",
    "        for x in board.ravel():\n",
    "            blank = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "            if x != 0:\n",
    "                blank[int(np.log2(x))] = 1\n",
    "            tokenized = np.append(tokenized, blank)\n",
    "        return tokenized\n",
    "    \n",
    "    def clear_memory(self, game):\n",
    "        if game.game_over == True:\n",
    "            self.memory = [[] for _ in range(self.reward_depth)]\n",
    "            self.long_memory = []\n",
    "            self.oldest_mem = 0\n",
    "    \n",
    "    def ai_suggest_move(self, game):\n",
    "        '''\n",
    "        method which takes the game and the model (the ai we are training) and suggests a move.\n",
    "        \n",
    "        Attributes:\n",
    "        Game(g2048 object): the game the AI is currently playing\n",
    "        \n",
    "        '''\n",
    "        self.bad_move = 0\n",
    "        board = game.board\n",
    "        \n",
    "        # tokenize_board block takes the game board and tokenizes all the arrays into 16 other arrays for if there's a 2, a 4, an 8, etc in a location to just a 1. hopefully...makes matching better\n",
    "\n",
    "        tokenized = self.tokenize_board(board) \n",
    "        \n",
    "        pred= self.model.predict(tokenized.reshape(1,-1))\n",
    "        output = [i for i in pred[0]]\n",
    "        \n",
    "        values = [2, 4, 6, 8]\n",
    "        valid_moves = game.valid_moves\n",
    "        \n",
    "        \n",
    "\n",
    "        d = dict(zip(np.array(output)[valid_moves], np.array(values)[valid_moves])) # all valid moves\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.demo == False: # only have random mvoe interference and gambling in learning rounds. \n",
    "            if np.random.randint(50+len(game.history)) < 3 and len(list(d.values())) > 0: # 5% of the time in the early game and decreasing as game length goes on, take random gamble moves to hopefully learn new tactics\n",
    "                rand_move = random.choice(list(d.values()))\n",
    "                self.memory.pop(0)\n",
    "                output.append(rand_move)\n",
    "                self.memory.append(np.array(output).reshape(1,-1))\n",
    "                if self.headless == False: \n",
    "                    print('random Move')\n",
    "                return rand_move\n",
    "        \n",
    "        if len(d.keys()) == 0:\n",
    "            #print('ai_suggest_move is out of possible moves')\n",
    "            game.game_over = True #game is over\n",
    "            return  -1\n",
    "\n",
    "        if game.strict == True:\n",
    "            if max(output) in d.keys(): #if the suggested move is not in valid_moves, it wont be in d, and so this will be negative, and the game will end\n",
    "                move = d.get(max(d.keys()))\n",
    "                self.memory.pop(0)\n",
    "                output.append(move)\n",
    "                self.long_memory.append(np.array(output).reshape(1,-1))\n",
    "                self.memory.append(np.array(output).reshape(1,-1))\n",
    "                return move\n",
    "            else:\n",
    "                game.game_over = True #game is over because this setting does not allow invaild moves:\n",
    "                return  -1\n",
    "        else:\n",
    "            if max(output) not in d.keys():\n",
    "                self.bad_move = -1 #triggers bad move if the thing has to take the next best move. \n",
    "                self.memory.pop()\n",
    "                self.memory.insert(0, self.oldest_mem) #puts the oldest memory back on because invalid moves do not update board\n",
    "            move = d.get(max(d.keys())) #takes the next best move that is valid\n",
    "            self.oldest_mem = self.memory.pop(0)\n",
    "            output.append(move)\n",
    "            self.long_memory.append(np.array(output).reshape(1,-1))\n",
    "            self.memory.append(np.array(output).reshape(1,-1))\n",
    "            \n",
    "            return move\n",
    "    \n",
    "    def calc_reward(self, game, move):\n",
    "        '''\n",
    "        Runs right after AI suggest move\n",
    "        checks if reinforcement is merited after the last move, if so, updates the fit of model. \n",
    "        Attributes\n",
    "        game (Game2048 object)\n",
    "        move (int): int passed from ai_suggest_move()\n",
    "        \n",
    "        Updates reward\n",
    "        \n",
    "        '''\n",
    "        self.reward = 0\n",
    "\n",
    "        \n",
    "        ## get old board and new board by checking move against the game's built in moves. \n",
    "        old_board = game.board\n",
    "        \n",
    "        if move == 2: \n",
    "            next_board = game.slide_down()\n",
    "        elif move == 4:\n",
    "            next_board = game.slide_left()\n",
    "        elif move == 6:\n",
    "            next_board = game.slide_right()\n",
    "        elif move == 8:\n",
    "            next_board = game.slide_up()\n",
    "        else:\n",
    "            next_board = np.array([[ 1,  1,  1,  1],  #simple full board for end-game board state comparison. \n",
    "                                   [ 1,  1, 1, 1],\n",
    "                                    [ 1, 1, 1,  1],\n",
    "                                   [ 1,  1,  1,  1]])\n",
    "        \n",
    "        tiles_combined = empties_state(old_board, next_board)\n",
    "        \n",
    "        \n",
    "        big_tiles = dict({32:6, 64: 6, 128: 10, 256: 10, 512: 20, 1024: 30, 2048: 100, 4096: 1000})\n",
    "        if np.amax(old_board) < np.amax(next_board): # checks to see if the bot has combined tiles or gotten a big one. \n",
    "            if np.amax(game.board) in big_tiles.keys():\n",
    "                self.reward += big_tiles[np.amax(game.board)]*2\n",
    "                if self.headless == False:    \n",
    "                    print('big tiles')\n",
    "            else: \n",
    "                self.reward +=4 \n",
    "                if self.headless == False:\n",
    "                    print('biggest tile yet')\n",
    "        else:\n",
    "            a = list(old_board.ravel())\n",
    "            b = list(next_board.ravel())\n",
    "            for i in big_tiles.keys():\n",
    "            \n",
    "                if b.count(i) - a.count(i) > 0:\n",
    "                    self.reward+= big_tiles[i]\n",
    "                    if self.headless == False:\n",
    "                        print('big tiles')\n",
    "        \n",
    "        \n",
    "        \n",
    "        if tiles_combined > 2:\n",
    "            self.reward += 1\n",
    "            if self.headless == False:\n",
    "                print('board managment bonus!')\n",
    "        \n",
    "        elif self.bad_move == -1 and len(game.history) > 10: # doesn't start penalizing for bad moves untill after a few turns of play\n",
    "            self.reward += -2\n",
    "            if self.headless == False:\n",
    "                print('invalid move')\n",
    "            \n",
    "        if game.game_over == True:\n",
    "            self.reward = -30\n",
    "            if self.headless == False:\n",
    "                print('game over penalty')\n",
    "        self.bad_move == 0 # Reset bad move!\n",
    "        old_score = game.score\n",
    "        \n",
    "    def give_reward(self, game):\n",
    "        '''if there is a reward, this will get the game history and the memory of the outputs, multiply the outputs by the reward and its time discount\n",
    "        \n",
    "        '''\n",
    "        values = [2, 4, 6, 8]\n",
    "        discount = 1\n",
    "        self.target = []\n",
    "        \n",
    "        if self.reward != 0:\n",
    "            #print('hey, the reward is this {}, so triggering reward steps'.format(self.reward))\n",
    "            if self.reward == -2:\n",
    "                h = game.history[-1]\n",
    "                m = self.memory[-2][0]\n",
    "                \n",
    "                self.debug = m\n",
    "                move = m[-1]\n",
    "                \n",
    "                items_short = m[:4]\n",
    "                self.debug1 = items_short\n",
    "                k = values.index(move)\n",
    "                #value in array that corresponds to the move taken  \n",
    "                items_short[k] = items_short[k]*self.reward\n",
    "                self.target.append(items_short)\n",
    "                \n",
    "                self.X = agent.tokenize_board(game.history[-1]).reshape(1,-1)\n",
    "                self.model.fit(np.array(self.X),np.array(self.target))\n",
    "                print ('trained on invalid move')\n",
    "                reward = 0 \n",
    "                self.debug2 = 0\n",
    "                return\n",
    "                \n",
    "            \n",
    "            elif len(game.history) <= self.reward_depth:\n",
    "                h = game.history[:-1]\n",
    "                m = self.memory[-(len(game.history)-1):] #indexes into the last last point in memory attached to the current game.\n",
    "                return # do nothing here to avoid unsolved index crash in items_short[0][:4]\n",
    "                self.debug2 = 1\n",
    "            else:\n",
    "                h = game.history[-(1+self.reward_depth):-1] #index into these arrays from the back, up to a height of however far the depth is\n",
    "                m = self.memory[-(1+self.reward_depth):] # memory is np array, game.history is list\n",
    "                self.debug2 = 2\n",
    "            #get moves \n",
    "            \n",
    "            \n",
    "            \n",
    "           \n",
    "            \n",
    "            for items in m:  ##make mem shotened to the length you want, currently its five. \n",
    "                self.debug1 = m\n",
    "                 #hacky nonsense way to check for this because it seems like the way I'm hadling these tensors is casting them into higher and lower order tensors\n",
    "                #self.debug = items\n",
    "                move = items[0][-1]\n",
    "\n",
    "                items_short = items[0][:4]\n",
    "                k = values.index(move)\n",
    "                #value in array that corresponds to the move taken\n",
    "\n",
    "                if self.reward*discount > 1:\n",
    "                    items_short[k] = items_short[k]*self.reward*discount\n",
    "                elif self.reward < 0:\n",
    "                    items_short[k] = items_short[k]*self.reward*discount\n",
    "                else:\n",
    "                    items_short[k] = items_short[k]*1.05\n",
    "                self.target.append(items_short)\n",
    "                discount -=(1/self.reward_depth)\n",
    "            self.X =[self.tokenize_board(i) for i in h]\n",
    "            print('reward: {}'.format(self.reward))\n",
    "            self.model.fit(np.array(self.X),np.array(self.target))\n",
    "            self.reward = 0\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "           \n",
    "            \n",
    "        \n",
    "        \n",
    "    def neural_net(self,):\n",
    "        '''\n",
    "        a method which creates a neural net for the agent\n",
    "        Returns:\n",
    "        model, a tensorflow nn\n",
    "        '''\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, activation='relu', input_dim = 256 ))\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        model.add(Dense(64, activation='relu') )\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        model.add(Dense(4, activation='softmax'))\n",
    "        opt = Adam(self.learning_rate)\n",
    "        \n",
    "        model.compile(loss='mse', optimizer=opt)\n",
    "\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:55:07.201826Z",
     "start_time": "2020-03-02T11:55:07.031636Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = RL_Player(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:55:07.206923Z",
     "start_time": "2020-03-02T11:55:07.203310Z"
    }
   },
   "outputs": [],
   "source": [
    "game = Game2048(ai = True, strict = False)\n",
    "scores = []\n",
    "best_tiles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:55:07.214411Z",
     "start_time": "2020-03-02T11:55:07.208531Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def print_move(x):\n",
    "    if x == 6:\n",
    "        print('slide right')\n",
    "    if x == 8:\n",
    "        print('slide up')\n",
    "    if x ==4:\n",
    "        print('slide left')\n",
    "    if x == 2:\n",
    "        print('slide down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:58:59.672812Z",
     "start_time": "2020-03-02T11:55:07.216847Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####------------------------------------] 9.8%\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(50):\n",
    "    agent.clear_memory(game)\n",
    "    game = Game2048(ai = True, headless = True, strict = False)\n",
    "    \n",
    "    print('new game')\n",
    "    print('')\n",
    "            \n",
    "\n",
    "    while game.game_over == False:\n",
    "        last_board = game.board\n",
    "        #print('Game Over: {}'.format(game.game_over))\n",
    "        \n",
    "        move = agent.ai_suggest_move(game)\n",
    "        game.show_board()\n",
    "        agent.calc_reward(game, move)\n",
    "             \n",
    "        agent.give_reward(game)\n",
    "        \n",
    "        game.get_move(move)\n",
    "        game.game_step()\n",
    "#         game.show_board()\n",
    "        print_move(move)\n",
    "#         print('')\n",
    "#         print('new move')\n",
    "#         print('')\n",
    "        \n",
    "        new_board = game.board\n",
    "    agent.calc_reward(game, move) # gives game-over rewards\n",
    "    #agent.give_reward(game)\n",
    "    \n",
    "    best_tiles.append(game.board.max())\n",
    "    scores.append(game.score)\n",
    "    update_progress(i/500)\n",
    "    print(game.board.max())\n",
    "        #print('reward: {}'.format(agent.reward))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T12:09:53.342796Z",
     "start_time": "2020-03-02T12:09:53.315663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 2 0 0]]\n",
      "\n",
      "[[0 0 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 2]]\n",
      "\n",
      "[[0 0 0 0]\n",
      " [2 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 2 2]]\n",
      "\n",
      "[[0 0 0 0]\n",
      " [0 0 0 2]\n",
      " [0 0 0 0]\n",
      " [2 0 2 2]]\n",
      "\n",
      "[[0 0 2 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [2 0 2 4]]\n",
      "\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [2 4 4 4]]\n",
      "\n",
      "[[0 0 2 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 2 4 8]]\n",
      "\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 2 2 0]\n",
      " [0 2 4 8]]\n",
      "\n",
      "[[0 0 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 2 0]\n",
      " [0 4 4 8]]\n",
      "\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [4 0 4 0]\n",
      " [0 4 4 8]]\n",
      "\n",
      "[[0 0 4 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [4 4 8 8]]\n",
      "\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 4 2]\n",
      " [4 4 8 8]]\n",
      "\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  0  0]\n",
      " [ 4  2  0  4]\n",
      " [ 8 16  0  0]]\n",
      "\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  0  4]\n",
      " [ 4  2  0  0]\n",
      " [ 8 16  0  4]]\n",
      "\n",
      "[[ 0  0  0  0]\n",
      " [ 4  2  0  0]\n",
      " [ 4  2  0  0]\n",
      " [ 8 16  4  0]]\n",
      "\n",
      "[[ 0  0  4  0]\n",
      " [ 0  0  0  0]\n",
      " [ 8  4  0  0]\n",
      " [ 8 16  4  0]]\n",
      "\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  2  0]\n",
      " [ 0  4  0  0]\n",
      " [16 16  8  0]]\n",
      "\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  0  0]\n",
      " [ 2  4  2  0]\n",
      " [16 16  8  0]]\n",
      "\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  0  0]\n",
      " [ 2  4  2  0]\n",
      " [32  8  2  0]]\n",
      "\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  2  0]\n",
      " [ 2  4  0  0]\n",
      " [32  8  4  0]]\n",
      "\n",
      "[[ 0  0  4  0]\n",
      " [ 0  0  0  2]\n",
      " [ 0  0  2  4]\n",
      " [ 0 32  8  4]]\n",
      "\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  4  0]\n",
      " [ 0  2  2  2]\n",
      " [ 0 32  8  8]]\n",
      "\n",
      "[[ 4  0  0  0]\n",
      " [ 4  0  0  0]\n",
      " [ 4  2  0  0]\n",
      " [32 16  0  0]]\n",
      "\n",
      "[[ 0  0  0  0]\n",
      " [ 8  0  0  0]\n",
      " [ 4  2  0  0]\n",
      " [32 16  2  0]]\n",
      "\n",
      "[[ 0  0  0  2]\n",
      " [ 0  0  0  8]\n",
      " [ 0  0  4  2]\n",
      " [ 0 32 16  2]]\n",
      "\n",
      "[[ 2  2  0  0]\n",
      " [ 8  0  0  0]\n",
      " [ 4  2  0  0]\n",
      " [32 16  2  0]]\n",
      "\n",
      "[[ 4  0  0  0]\n",
      " [ 8  0  0  0]\n",
      " [ 4  2  2  0]\n",
      " [32 16  2  0]]\n",
      "\n",
      "[[ 4  0  0  0]\n",
      " [ 8  0  0  0]\n",
      " [ 4  2  0  0]\n",
      " [32 16  4  2]]\n",
      "\n",
      "[[ 0  0  2  4]\n",
      " [ 0  0  0  8]\n",
      " [ 0  0  4  2]\n",
      " [32 16  4  2]]\n",
      "\n",
      "[[ 2  0  0  0]\n",
      " [ 0  0  0  4]\n",
      " [ 0  0  2  8]\n",
      " [32 16  8  4]]\n",
      "\n",
      "[[ 0  0  2  0]\n",
      " [ 0  0  0  4]\n",
      " [ 2  0  2  8]\n",
      " [32 16  8  4]]\n",
      "\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  2  4]\n",
      " [ 2  0  4  8]\n",
      " [32 16  8  4]]\n",
      "\n",
      "[[ 0  0  0  4]\n",
      " [ 0  0  2  4]\n",
      " [ 0  2  4  8]\n",
      " [32 16  8  4]]\n",
      "\n",
      "[[ 2  0  0  0]\n",
      " [ 0  0  2  8]\n",
      " [ 0  2  4  8]\n",
      " [32 16  8  4]]\n",
      "\n",
      "[[ 0  0  0  4]\n",
      " [ 0  0  2  0]\n",
      " [ 2  2  4 16]\n",
      " [32 16  8  4]]\n",
      "\n",
      "[[ 0  0  0  4]\n",
      " [ 0  0  0  2]\n",
      " [ 2  4  4 16]\n",
      " [32 16  8  4]]\n",
      "\n",
      "[[ 0  0  0  4]\n",
      " [ 2  0  0  2]\n",
      " [ 0  2  8 16]\n",
      " [32 16  8  4]]\n",
      "\n",
      "[[ 4  0  0  0]\n",
      " [ 4  0  4  0]\n",
      " [ 2  8 16  0]\n",
      " [32 16  8  4]]\n",
      "\n",
      "[[ 0  0  0  2]\n",
      " [ 8  0  4  0]\n",
      " [ 2  8 16  0]\n",
      " [32 16  8  4]]\n",
      "\n",
      "[[ 0  4  0  0]\n",
      " [ 8  0  4  0]\n",
      " [ 2  8 16  2]\n",
      " [32 16  8  4]]\n",
      "\n",
      "[[ 2  0  0  0]\n",
      " [ 8  4  4  0]\n",
      " [ 2  8 16  2]\n",
      " [32 16  8  4]]\n",
      "\n",
      "[[ 2  0  0  2]\n",
      " [ 0  0  8  8]\n",
      " [ 2  8 16  2]\n",
      " [32 16  8  4]]\n",
      "\n",
      "[[ 0  0  0  2]\n",
      " [ 2  0  8  8]\n",
      " [ 4  8 16  2]\n",
      " [32 16  8  4]]\n",
      "\n",
      "[[ 0  0  4  2]\n",
      " [ 0  0  2 16]\n",
      " [ 4  8 16  2]\n",
      " [32 16  8  4]]\n",
      "\n",
      "[[ 4  8  4  2]\n",
      " [32 16  2 16]\n",
      " [ 0  2 16  2]\n",
      " [ 0  0  8  4]]\n",
      "\n",
      "[[ 2  0  4  2]\n",
      " [ 0  8  2 16]\n",
      " [ 4 16 16  2]\n",
      " [32  2  8  4]]\n",
      "\n",
      "[[ 2  2  4  2]\n",
      " [ 0  8  2 16]\n",
      " [ 0  4 32  2]\n",
      " [32  2  8  4]]\n",
      "\n",
      "[[ 2  4  4  2]\n",
      " [ 0  8  2 16]\n",
      " [ 0  4 32  2]\n",
      " [32  2  8  4]]\n",
      "\n",
      "[[ 2  2  8  2]\n",
      " [ 0  8  2 16]\n",
      " [ 0  4 32  2]\n",
      " [32  2  8  4]]\n",
      "\n",
      "[[ 2  4  8  2]\n",
      " [ 0  8  2 16]\n",
      " [ 0  4 32  2]\n",
      " [32  2  8  4]]\n",
      "\n",
      "[[ 2  4  8  2]\n",
      " [ 8  2 16  2]\n",
      " [ 4 32  2  0]\n",
      " [32  2  8  4]]\n",
      "\n",
      "[[ 2  4  8  4]\n",
      " [ 8  2 16  4]\n",
      " [ 4 32  2  2]\n",
      " [32  2  8  0]]\n",
      "\n",
      "[[ 2  4  8  4]\n",
      " [ 8  2 16  4]\n",
      " [ 4 32  4  2]\n",
      " [32  2  8  0]]\n",
      "\n",
      "[[ 2  4  8  4]\n",
      " [ 8  2 16  4]\n",
      " [ 4 32  4  2]\n",
      " [ 2 32  2  8]]\n",
      "\n",
      "[[ 2  0  8  2]\n",
      " [ 8  4 16  8]\n",
      " [ 4  2  4  2]\n",
      " [ 2 64  2  8]]\n",
      "\n",
      "[[ 2  8  2  4]\n",
      " [ 8  4 16  8]\n",
      " [ 4  2  4  2]\n",
      " [ 2 64  2  8]]\n"
     ]
    }
   ],
   "source": [
    "for i in game.history:\n",
    "    print('')\n",
    "    print(i.reshape(4,4))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T12:08:49.987344Z",
     "start_time": "2020-03-02T12:08:49.970469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.28457183, 0.22300322, 0.27599838, 0.21642654, 2.        ]]),\n",
       " array([[0.2905387 , 0.24591221, 0.27799472, 0.18555441, 2.        ]]),\n",
       " array([[0.28311852, 0.26175189, 0.26134905, 0.19378054, 2.        ]]),\n",
       " array([[0.28311852, 0.26175189, 0.26134905, 0.19378054, 4.        ]]),\n",
       " array([[0.28698263, 0.2540279 , 0.27408034, 0.18490906, 2.        ]]),\n",
       " array([[0.2734867 , 0.26305574, 0.27548823, 0.18796939, 6.        ]]),\n",
       " array([[0.2869986 , 0.22297493, 0.27774301, 0.21228354, 2.        ]]),\n",
       " array([[0.28033248, 0.28108048, 0.22507563, 0.21351129, 4.        ]]),\n",
       " array([[0.26865405, 0.2812303 , 0.26352659, 0.18658906, 4.        ]]),\n",
       " array([[0.26865405, 0.2812303 , 0.26352659, 0.18658906, 2.        ]]),\n",
       " array([[0.29412198, 0.24263068, 0.27950475, 0.18374263, 2.        ]]),\n",
       " array([[0.29412198, 0.24263068, 0.27950475, 0.18374263, 6.        ]]),\n",
       " array([[0.26174062, 0.27885544, 0.19247541, 0.26692849, 4.        ]]),\n",
       " array([[0.25526392, 0.28009632, 0.26458693, 0.20005278, 4.        ]]),\n",
       " array([[0.29199049, 0.24332963, 0.27840117, 0.18627864, 2.        ]]),\n",
       " array([[0.28636807, 0.22738867, 0.27654654, 0.20969678, 2.        ]]),\n",
       " array([[0.28636807, 0.22738867, 0.27654654, 0.20969678, 6.        ]]),\n",
       " array([[0.28163296, 0.27160075, 0.23495725, 0.2118091 , 2.        ]]),\n",
       " array([[0.28862277, 0.21957538, 0.28275469, 0.20904723, 2.        ]]),\n",
       " array([[0.28503716, 0.24013986, 0.27223703, 0.202586  , 2.        ]]),\n",
       " array([[0.28708091, 0.22407115, 0.27941385, 0.20943403, 2.        ]]),\n",
       " array([[0.28708091, 0.22407115, 0.27941385, 0.20943403, 6.        ]]),\n",
       " array([[0.2921024 , 0.22826277, 0.28513122, 0.19450371, 2.        ]]),\n",
       " array([[0.28920779, 0.24129419, 0.28161266, 0.18788534, 2.        ]]),\n",
       " array([[0.2778036 , 0.25133088, 0.28266904, 0.18819651, 6.        ]]),\n",
       " array([[0.27318156, 0.26486534, 0.27585319, 0.18609987, 6.        ]]),\n",
       " array([[0.11825372, 0.35900459, 0.21669693, 0.30604473, 4.        ]]),\n",
       " array([[0.28328133, 0.26305458, 0.2497711 , 0.20389299, 2.        ]]),\n",
       " array([[0.28566426, 0.23661131, 0.27002206, 0.20770238, 2.        ]]),\n",
       " array([[0.28633893, 0.23270483, 0.27647865, 0.20447756, 2.        ]]),\n",
       " array([[0.2852248 , 0.23751482, 0.26856023, 0.20870021, 2.        ]]),\n",
       " array([[0.2852248 , 0.23751482, 0.26856023, 0.20870021, 6.        ]]),\n",
       " array([[0.28414473, 0.20941803, 0.27767456, 0.22876264, 2.        ]]),\n",
       " array([[0.27866459, 0.1944617 , 0.28320152, 0.24367216, 6.        ]]),\n",
       " array([[0.28058594, 0.197412  , 0.2887699 , 0.23323211, 6.        ]]),\n",
       " array([[0.28058594, 0.197412  , 0.2887699 , 0.23323211, 2.        ]]),\n",
       " array([[0.28185251, 0.19908412, 0.29171154, 0.22735187, 8.        ]]),\n",
       " array([[0.25343788, 0.23096724, 0.22505604, 0.29053885, 8.        ]]),\n",
       " array([[0.25343788, 0.23096724, 0.22505604, 0.29053885, 2.        ]]),\n",
       " array([[0.27847606, 0.2054375 , 0.29487953, 0.22120692, 6.        ]]),\n",
       " array([[0.27951992, 0.20801666, 0.28290606, 0.22955729, 6.        ]]),\n",
       " array([[0.28168374, 0.20340079, 0.28831047, 0.22660494, 6.        ]]),\n",
       " array([[0.25803912, 0.25906584, 0.28157496, 0.20132011, 6.        ]]),\n",
       " array([[0.22520791, 0.28369802, 0.26531047, 0.22578363, 4.        ]]),\n",
       " array([[0.06553976, 0.37327176, 0.1860812 , 0.37510729, 8.        ]]),\n",
       " array([[0.25500286, 0.27934155, 0.26953852, 0.19611704, 4.        ]]),\n",
       " array([[0.26483452, 0.26402816, 0.27780765, 0.19332963, 6.        ]]),\n",
       " array([[0.25620991, 0.27366564, 0.27225685, 0.19786765, 4.        ]]),\n",
       " array([[0.25620991, 0.27366564, 0.27225685, 0.19786765, 6.        ]]),\n",
       " array([[0.25669229, 0.27378315, 0.27263057, 0.19689403, 2.        ]]),\n",
       " array([[0.28594077, 0.26688549, 0.2628853 , 0.18428838, 2.        ]]),\n",
       " array([[0.28594077, 0.26688549, 0.2628853 , 0.18428838, 4.        ]]),\n",
       " array([[0.29051948, 0.25235283, 0.27529299, 0.18183476, 2.        ]]),\n",
       " array([[0.29051948, 0.25235283, 0.27529299, 0.18183476, 6.        ]]),\n",
       " array([[0.29060429, 0.25082925, 0.27648273, 0.1820837 , 4.        ]]),\n",
       " array([[0.29103264, 0.24768376, 0.27866679, 0.18261677, 8.        ]])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.long_memory[-56:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:58:59.702637Z",
     "start_time": "2020-03-02T11:58:59.674630Z"
    }
   },
   "outputs": [],
   "source": [
    "agent.model.save('fixed a prlbem.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.035232Z",
     "start_time": "2020-03-02T11:58:59.704311Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kka' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3a72b25e6417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkka\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'kka' is not defined"
     ]
    }
   ],
   "source": [
    "kka +k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.038412Z",
     "start_time": "2020-03-02T11:55:04.991Z"
    }
   },
   "outputs": [],
   "source": [
    "j = [i for i in zip((scores, best_tiles))]\n",
    "fig, ax = plt.subplots(1,3, figsize = (18,6))\n",
    "ax[0].hist(j[0], bins = 12)\n",
    "ax[0].set_title('histogram of game scores')\n",
    "ax[0].set_xlabel('number of games')\n",
    "ax[0].set_ylabel('final score')\n",
    "\n",
    "ax[1].hist(j[1], bins = 10)\n",
    "ax[1].set_title('histograms of best tiles reached')\n",
    "ax[1].set_xlabel('tile value')\n",
    "ax[1].set_ylabel('number of games')\n",
    "\n",
    "move_avg = np.convolve(scores, np.ones((10,))/10, mode='valid')    \n",
    "ax[2].plot(move_avg)\n",
    "ax[2].set_title('score over evolutions')\n",
    "ax[2].set_xlabel('number of games')\n",
    "ax[2].set_ylabel('score')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.039915Z",
     "start_time": "2020-03-02T11:55:05.001Z"
    }
   },
   "outputs": [],
   "source": [
    "gens = enumerate(scores)\n",
    "fig, ax = plt.plot(gens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.041426Z",
     "start_time": "2020-03-02T11:55:05.006Z"
    }
   },
   "outputs": [],
   "source": [
    "j = [(i, j)for i, j in enumerate(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.042870Z",
     "start_time": "2020-03-02T11:55:05.012Z"
    }
   },
   "outputs": [],
   "source": [
    "move_avg_tiles = np.convolve(best_tiles, np.ones((10,))/10, mode='valid')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.044391Z",
     "start_time": "2020-03-02T11:55:05.016Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.log2(move_avg_tiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.045765Z",
     "start_time": "2020-03-02T11:55:05.025Z"
    }
   },
   "outputs": [],
   "source": [
    "agent.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.047516Z",
     "start_time": "2020-03-02T11:55:05.032Z"
    }
   },
   "outputs": [],
   "source": [
    "#agent.model.save('my_model.h5') \n",
    "\n",
    "#new_model = keras.models.load_model('my_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.049095Z",
     "start_time": "2020-03-02T11:55:05.038Z"
    }
   },
   "outputs": [],
   "source": [
    "def demo_QR_learner(ai_path, headless = True):\n",
    "    '''\n",
    "    function that runs the AI without training it for showcasing and metrics of the AI at specific training levels. \n",
    "    Attributes \n",
    "    ai_path (str): path of the ai model\n",
    "    Returns\n",
    "    tuple (biggest tile reached, score of game)\n",
    "    '''\n",
    "    agent = RL_Player(model = ai_path, demo = True)\n",
    "    game = Game2048(ai = True, headless = False, strict = False)\n",
    "\n",
    "    \n",
    "\n",
    "    while game.game_over == False:\n",
    "        last_board = game.board\n",
    "        #print('Game Over: {}'.format(game.game_over))\n",
    "\n",
    "        move = agent.ai_suggest_move(game)\n",
    "        if headless == False:\n",
    "            game.show_board()\n",
    "        #agent.calc_reward(game, move)\n",
    "\n",
    "        #agent.give_reward(game)\n",
    "\n",
    "        game.get_move(move)\n",
    "        game.game_step()\n",
    "        if headless == False:\n",
    "            print_move(move)\n",
    "            print('')\n",
    "\n",
    "        new_board = game.board\n",
    "    return game.board.max(), game.score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.050552Z",
     "start_time": "2020-03-02T11:55:05.042Z"
    }
   },
   "outputs": [],
   "source": [
    "def ai_averages(ai_path, num_runs, is_strict = False):\n",
    "\n",
    "    \n",
    "    scores = []\n",
    "    best_tiles = []\n",
    "    empties = []\n",
    "    for i in range(num_runs):\n",
    "        \n",
    "        \n",
    "\n",
    "        tile, score = demo_QR_learner(ai_path, headless = True)\n",
    "\n",
    "        print(i)        \n",
    "        \n",
    "        \n",
    "        best_tiles.append(tile)\n",
    "        scores.append(score)\n",
    "        update_progress(i/num_runs)  \n",
    "    return best_tiles, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.051997Z",
     "start_time": "2020-03-02T11:55:05.047Z"
    }
   },
   "outputs": [],
   "source": [
    "#tiles, scores = ai_averages('my_model.h5', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.053411Z",
     "start_time": "2020-03-02T11:55:05.052Z"
    }
   },
   "outputs": [],
   "source": [
    "#demo_QR_learner('my_model.h5', headless = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 500 Gen Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.054868Z",
     "start_time": "2020-03-02T11:55:05.058Z"
    }
   },
   "outputs": [],
   "source": [
    "tiles500, scores500 = ai_averages('Q500.h5', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.056447Z",
     "start_time": "2020-03-02T11:55:05.062Z"
    }
   },
   "outputs": [],
   "source": [
    "#tiles500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.058028Z",
     "start_time": "2020-03-02T11:55:05.067Z"
    }
   },
   "outputs": [],
   "source": [
    "tiles1000, scores1000 = ai_averages('Q1000.h5', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.059403Z",
     "start_time": "2020-03-02T11:55:05.072Z"
    }
   },
   "outputs": [],
   "source": [
    "#tiles1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.060736Z",
     "start_time": "2020-03-02T11:55:05.078Z"
    }
   },
   "outputs": [],
   "source": [
    "tiles1500, scores1500 = ai_averages('Q1500.h5', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.062204Z",
     "start_time": "2020-03-02T11:55:05.082Z"
    }
   },
   "outputs": [],
   "source": [
    "#tiles1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.063712Z",
     "start_time": "2020-03-02T11:55:05.086Z"
    }
   },
   "outputs": [],
   "source": [
    "tiles2000, scores2000 = ai_averages('Q2000.h5', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.065227Z",
     "start_time": "2020-03-02T11:55:05.092Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (10,4))\n",
    "\n",
    "fig.suptitle('performance after 500 generations', fontsize=16)\n",
    "ax[0].hist(scores500, bins = 12)\n",
    "ax[0].set_title('number of games')\n",
    "ax[0].set_xlabel('histogram of game scores')\n",
    "ax[0].set_ylabel('final score')\n",
    "\n",
    "ax[1].hist(tiles500, bins = 10)\n",
    "ax[1].set_title('histograms of best tiles reached')\n",
    "ax[1].set_xlabel('tile value')\n",
    "ax[1].set_ylabel('number of games')\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.066782Z",
     "start_time": "2020-03-02T11:55:05.097Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (10,4))\n",
    "\n",
    "fig.suptitle('performance after 1000 generations', fontsize=16)\n",
    "ax[0].hist(scores1000, bins = 12)\n",
    "ax[0].set_title('number of games')\n",
    "ax[0].set_xlabel('histogram of game scores')\n",
    "ax[0].set_ylabel('final score')\n",
    "\n",
    "ax[1].hist(tiles1000, bins = 10)\n",
    "ax[1].set_title('histograms of best tiles reached')\n",
    "ax[1].set_xlabel('tile value')\n",
    "ax[1].set_ylabel('number of games')\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.068285Z",
     "start_time": "2020-03-02T11:55:05.102Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (10,4))\n",
    "\n",
    "fig.suptitle('performance after 1500 generations', fontsize=16)\n",
    "ax[0].hist(scores1500, bins = 12)\n",
    "ax[0].set_title('number of games')\n",
    "ax[0].set_xlabel('histogram of game scores')\n",
    "ax[0].set_ylabel('final score')\n",
    "\n",
    "ax[1].hist(tiles1500, bins = 10)\n",
    "ax[1].set_title('histograms of best tiles reached')\n",
    "ax[1].set_xlabel('tile value')\n",
    "ax[1].set_ylabel('number of games')\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.069743Z",
     "start_time": "2020-03-02T11:55:05.104Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,3, figsize = (10,4))\n",
    "\n",
    "fig.suptitle('performance after 2000 generations', fontsize=16)\n",
    "ax[0].hist(scores2000, bins = 12)\n",
    "ax[0].set_title('number of games')\n",
    "ax[0].set_xlabel('histogram of game scores')\n",
    "ax[0].set_ylabel('final score')\n",
    "\n",
    "ax[1].hist(tiles2000, bins = 10)\n",
    "ax[1].set_title('histograms of best tiles reached')\n",
    "ax[1].set_xlabel('tile value')\n",
    "ax[1].set_ylabel('number of games')\n",
    "\n",
    "ax[2].bar(t3, v3, align='center', alpha=0.5)\n",
    "#ax[0].xticks(y_pos, objects)\n",
    "ax[2].set_ylabel('Frequency')\n",
    "ax[2].set_xlabel('tile value')\n",
    "ax[2].set_title('2000 games')\n",
    "\n",
    "\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.071159Z",
     "start_time": "2020-03-02T11:55:05.106Z"
    }
   },
   "outputs": [],
   "source": [
    "len(tiles1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.072661Z",
     "start_time": "2020-03-02T11:55:05.108Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.074177Z",
     "start_time": "2020-03-02T11:55:05.111Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(tiles2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.075902Z",
     "start_time": "2020-03-02T11:55:05.113Z"
    }
   },
   "outputs": [],
   "source": [
    "tiles = Counter(tiles500)\n",
    "tiles1 = Counter(tiles1000)\n",
    "tiles2 = Counter(tiles1500)\n",
    "tiles3 = Counter(tiles2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.077422Z",
     "start_time": "2020-03-02T11:55:05.115Z"
    }
   },
   "outputs": [],
   "source": [
    "a = list(tiles.values())\n",
    "b = list(tiles.keys())\n",
    "s = sorted(zip(a,b))\n",
    "t,v0 = map(list, zip(*s))\n",
    "t0 = [str(i) for i in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.078899Z",
     "start_time": "2020-03-02T11:55:05.118Z"
    }
   },
   "outputs": [],
   "source": [
    "tiles = Counter(tiles500)\n",
    "v = list(tiles1.values())\n",
    "t = list(tiles1.keys())\n",
    "s = sorted(zip(t,v))\n",
    "t,v1 = map(list, zip(*s))\n",
    "t1 = [str(i) for i in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.080393Z",
     "start_time": "2020-03-02T11:55:05.120Z"
    }
   },
   "outputs": [],
   "source": [
    "v = list(tiles2.values())\n",
    "t = list(tiles2.keys())\n",
    "s = sorted(zip(t,v))\n",
    "t,v2 = map(list, zip(*s))\n",
    "t2 = [str(i) for i in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.082031Z",
     "start_time": "2020-03-02T11:55:05.123Z"
    }
   },
   "outputs": [],
   "source": [
    "v = list(tiles3.values())\n",
    "t = list(tiles3.keys())\n",
    "s = sorted(zip(t,v))\n",
    "t,v3 = map(list, zip(*s))\n",
    "t3 = [str(i) for i in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.083429Z",
     "start_time": "2020-03-02T11:55:05.125Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pos = t\n",
    "performance = v\n",
    "\n",
    "fig, ax = plt.subplots(1,4, figsize = (10,4))\n",
    "\n",
    "ax[0].bar(t0, v0, align='center', color = 'k')\n",
    "#ax[0].xticks(y_pos, objects)\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[0].set_xlabel('tile value')\n",
    "ax[0].set_title('by 500 games')\n",
    "\n",
    "ax[1].bar(t1, v1, align='center', color = 'k')\n",
    "#ax[0].xticks(y_pos, objects)\n",
    "ax[1].set_ylabel('Frequency')\n",
    "ax[1].set_xlabel('tile value')\n",
    "ax[1].set_title('by of 1000 games')\n",
    "\n",
    "ax[2].bar(t2, v2, align='center', color = 'k')\n",
    "#ax[0].xticks(y_pos, objects)\n",
    "ax[2].set_ylabel('Frequency')\n",
    "ax[2].set_xlabel('tile value')\n",
    "ax[2].set_title('by 1500 games')\n",
    "\n",
    "ax[3].bar(t3, v3, align='center',  color = 'k')\n",
    "#ax[0].xticks(y_pos, objects)\n",
    "ax[3].set_ylabel('Frequency')\n",
    "ax[3].set_xlabel('tile value')\n",
    "ax[3].set_title('by 2000 games')\n",
    "\n",
    "plt.suptitle('Best tiles reached with 100 trials')\n",
    "\n",
    "plt.savefig('best tile reached by Q-Learner Bar.png')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, .90])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.084621Z",
     "start_time": "2020-03-02T11:55:05.126Z"
    }
   },
   "outputs": [],
   "source": [
    "all_scores = scores500+scores1000+scores1500+scores2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.085506Z",
     "start_time": "2020-03-02T11:55:05.129Z"
    }
   },
   "outputs": [],
   "source": [
    "moving_avg = np.convolve(all_scores, np.ones((10,))/10, mode='valid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.086344Z",
     "start_time": "2020-03-02T11:55:05.132Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(moving_avg, color = 'k', linewidth = 1.2)\n",
    "\n",
    "ax.set_xticklabels(xtickslist)\n",
    "\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Game Iterations')\n",
    "ax.set_title('Q-Learning Score per Games Played')\n",
    "plt.savefig('Q-Learning Score per Games Played.png')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.087284Z",
     "start_time": "2020-03-02T11:55:05.134Z"
    }
   },
   "outputs": [],
   "source": [
    "xtickslist = [str(200*i) for i in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T11:59:00.088177Z",
     "start_time": "2020-03-02T11:55:05.136Z"
    }
   },
   "outputs": [],
   "source": [
    "xtickslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python37464bitanaconda3virtualenv4689841a946143dd80c9fcc86c644564"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
